{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a8473cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "676b0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "\n",
    "data=pd.read_csv('preprocessed_UK_Accidents_2009_updated.csv',index_col='accident_index')\n",
    "data=data.drop('seasons_ranges',axis=1)\n",
    "x = data.drop('accident_severity', axis=1) \n",
    "y = data['accident_severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1c879720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalling data\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f5d881d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "priciple_component_analayzer = PCA(n_components=15) # based on domain knowledge from feature extraction notebook\n",
    "x_pca = priciple_component_analayzer.fit_transform(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ae278f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    134714\n",
       "2     21475\n",
       "3      2003\n",
       "Name: accident_severity, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Imbalance\n",
    "class_counts = y.value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As shown above the data suffer from sever data imbalance\n",
    "## Solutions:\n",
    "## 1-class weights (not available in NB, but prior probabilities can be adjusted to treate each class according to \n",
    "## its occurrence)\n",
    "## 2- Resampling (random resampling will be used in our case )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4f4fe2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gaussian NB\n",
    "## This model assumes that all features are normally distributed, which could be a problem in our case. So, we will be testing\n",
    "## first on a base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "152a0722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8519741490224076\n",
      "Testing accuracy: 0.8493826119937629\n",
      "Training F1 score: 0.8519741490224076\n",
      "Testing F1 score: 0.8493826119937629\n",
      "Training precision: 0.8519741490224076\n",
      "Testing precision: 0.8493826119937629\n",
      "Training recall: 0.8519741490224076\n",
      "Testing recall: 0.8493826119937629\n"
     ]
    }
   ],
   "source": [
    "## base model with data before pca\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the training and testing data\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "y_test_pred = gnb.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='micro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred, average='micro')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred, average='micro')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Testing accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"Training F1 score:\", train_f1)\n",
    "print(\"Testing F1 score:\", test_f1)\n",
    "\n",
    "print(\"Training precision:\", train_precision)\n",
    "print(\"Testing precision:\", test_precision)\n",
    "\n",
    "print(\"Training recall:\", train_recall)\n",
    "print(\"Testing recall:\", test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f00efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8457865732580709\n",
      "Testing accuracy: 0.8432719457204265\n",
      "Training F1 score: 0.8457865732580709\n",
      "Testing F1 score: 0.8432719457204265\n",
      "Training precision: 0.8457865732580709\n",
      "Testing precision: 0.8432719457204265\n",
      "Training recall: 0.8457865732580709\n",
      "Testing recall: 0.8432719457204265\n"
     ]
    }
   ],
   "source": [
    "## base model with data after pca\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the training and testing data\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "y_test_pred = gnb.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='micro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred, average='micro')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred, average='micro')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Testing accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"Training F1 score:\", train_f1)\n",
    "print(\"Testing F1 score:\", test_f1)\n",
    "\n",
    "print(\"Training precision:\", train_precision)\n",
    "print(\"Testing precision:\", test_precision)\n",
    "\n",
    "print(\"Training recall:\", train_recall)\n",
    "print(\"Testing recall:\", test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "747f1aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.20061280798435258\n",
      "Testing accuracy: 0.2025369800665852\n",
      "Training F1 score: 0.2006128079843526\n",
      "Testing F1 score: 0.2025369800665852\n",
      "Training precision: 0.20061280798435258\n",
      "Testing precision: 0.2025369800665852\n",
      "Training recall: 0.20061280798435258\n",
      "Testing recall: 0.2025369800665852\n"
     ]
    }
   ],
   "source": [
    "## base model with data after pca and normalization\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the training and testing data\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "y_test_pred = gnb.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='micro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred, average='micro')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred, average='micro')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Testing accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"Training F1 score:\", train_f1)\n",
    "print(\"Testing F1 score:\", test_f1)\n",
    "\n",
    "print(\"Training precision:\", train_precision)\n",
    "print(\"Testing precision:\", test_precision)\n",
    "\n",
    "print(\"Training recall:\", train_recall)\n",
    "print(\"Testing recall:\", test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92c555d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From the results above scalling really degraded the performance of the model. Moreover, the PCA reduced \n",
    "## the performance by a very small percentage. Therefore, PCA data will be used to reduce \n",
    "## features in order to save computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c969bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.4489724033535165\n",
      "Testing accuracy: 0.4470489261324272\n",
      "Training F1 score: 0.44897240335351657\n",
      "Testing F1 score: 0.4470489261324272\n",
      "Training precision: 0.4489724033535165\n",
      "Testing precision: 0.4470489261324272\n",
      "Training recall: 0.4489724033535165\n",
      "Testing recall: 0.4470489261324272\n"
     ]
    }
   ],
   "source": [
    "oversampler = RandomOverSampler(random_state=10)\n",
    "x_resampled, y_resampled = oversampler.fit_resample(x_pca, y)\n",
    "x_resampled=pd.DataFrame(x_resampled)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.15, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the training and testing data\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "y_test_pred = gnb.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='micro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred, average='micro')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred, average='micro')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Testing accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"Training F1 score:\", train_f1)\n",
    "print(\"Testing F1 score:\", test_f1)\n",
    "\n",
    "print(\"Training precision:\", train_precision)\n",
    "print(\"Testing precision:\", test_precision)\n",
    "\n",
    "print(\"Training recall:\", train_recall)\n",
    "print(\"Testing recall:\", test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861db75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## resampling\n",
    "oversampler = RandomOverSampler(random_state=10)\n",
    "x_resampled, y_resampled = oversampler.fit_resample(x_pca, y)\n",
    "x_resampled=pd.DataFrame(x_resampled)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.15, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the training and testing data\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "y_test_pred = gnb.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='micro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred, average='micro')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred, average='micro')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Testing accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"Training F1 score:\", train_f1)\n",
    "print(\"Testing F1 score:\", test_f1)\n",
    "\n",
    "print(\"Training precision:\", train_precision)\n",
    "print(\"Testing precision:\", test_precision)\n",
    "\n",
    "print(\"Training recall:\", train_recall)\n",
    "print(\"Testing recall:\", test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "256c35b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.85158542 0.13575276 0.01266183]\n"
     ]
    }
   ],
   "source": [
    "## Prriors\n",
    "# Compute the number of samples for each class\n",
    "class_counts = np.bincount(y)\n",
    "\n",
    "# Compute the prior probabilities of each class\n",
    "priors = class_counts / len(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02824128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.34161911970190967\n",
      "Testing accuracy: 0.34108079575071754\n",
      "Training F1 score: 0.34161911970190967\n",
      "Testing F1 score: 0.34108079575071754\n",
      "Training precision: 0.34161911970190967\n",
      "Testing precision: 0.34108079575071754\n",
      "Training recall: 0.34161911970190967\n",
      "Testing recall: 0.34108079575071754\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.15, random_state=42)\n",
    "# Create a Gaussian Naive Bayes model\n",
    "prior_prob = np.array([0.85158542 , 0.13575276, 0.01266183])\n",
    "gnb = GaussianNB(priors=prior_prob)\n",
    "\n",
    "# Train the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the model on the training and testing data\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "y_test_pred = gnb.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='micro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_precision = precision_score(y_train, y_train_pred, average='micro')\n",
    "test_precision = precision_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "train_recall = recall_score(y_train, y_train_pred, average='micro')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Testing accuracy:\", test_accuracy)\n",
    "\n",
    "print(\"Training F1 score:\", train_f1)\n",
    "print(\"Testing F1 score:\", test_f1)\n",
    "\n",
    "print(\"Training precision:\", train_precision)\n",
    "print(\"Testing precision:\", test_precision)\n",
    "\n",
    "print(\"Training recall:\", train_recall)\n",
    "print(\"Testing recall:\", test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da75aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## as the results show the priors made the performance of the model worse. Therefore we will work with the imbalanced data, \n",
    "## although it's expected that this model wont yield good results as it assumes that the features are normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d13adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## anothe model is Multinomial Naive Bayes, but we wont use it as, Multinomial Naive Bayes assumes that the features \n",
    "## are counts of occurrences of different events. Our data is not suitable as it contains numerical data and not categorical\n",
    "## data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b91f58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.15, random_state=10,stratify=y)## stratify=y used to have the same ration of classes in each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2b4cef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "Best hyperparameters: {'var_smoothing': 0.1}\n",
      "Best accuracy: 0.8497727881080065\n",
      "Best precision: 0.8497727881080065\n",
      "Best recall: 0.8497727881080065\n",
      "Best F1 score: 0.8497727881080065\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]}\n",
    "# Create a Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Define custom scoring functions to calculate accuracy, precision, recall, and F1 score with average='macro'\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "precision_scorer = make_scorer(precision_score, average='micro', zero_division=0)\n",
    "recall_scorer = make_scorer(recall_score, average='micro')\n",
    "f1_scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# Perform grid search and obtain performance metrics for each combination of hyperparameters\n",
    "grid_search = GridSearchCV(gnb, param_grid=param_grid, cv=StratifiedKFold(n_splits=2, random_state=10, shuffle=True),\n",
    "                           scoring={'accuracy': accuracy_scorer, 'precision': precision_scorer, 'recall': recall_scorer, 'f1': f1_scorer},\n",
    "                           refit='precision', verbose=3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and corresponding performance metrics\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)\n",
    "print(\"Best precision:\", grid_search.cv_results_['mean_test_precision'][grid_search.best_index_])\n",
    "print(\"Best recall:\", grid_search.cv_results_['mean_test_recall'][grid_search.best_index_])\n",
    "print(\"Best F1 score:\", grid_search.cv_results_['mean_test_f1'][grid_search.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f68a8441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8496538081107814\n",
      "Training precision: 0.8496538081107814\n",
      "Training recall: 0.8496538081107814\n",
      "Training F1 score: 0.8496538081107814\n",
      "Testing accuracy: 0.8491297568376248\n",
      "Testing precision: 0.8491297568376248\n",
      "Testing recall: 0.8491297568376248\n",
      "Testing F1 score: 0.8491297568376248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Create a Gaussian Naive Bayes model with the best var_smoothing parameter\n",
    "gnb = GaussianNB(var_smoothing=0.1)\n",
    "\n",
    "# Train the model on the training set\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set and calculate performance metrics\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, average='micro', zero_division=0)\n",
    "train_recall = recall_score(y_train, y_train_pred, average='micro')\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='micro')\n",
    "\n",
    "# Make predictions on the testing set and calculate performance metrics\n",
    "y_test_pred = gnb.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='micro', zero_division=0)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='micro')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Training accuracy:\", train_accuracy)\n",
    "print(\"Training precision:\", train_precision)\n",
    "print(\"Training recall:\", train_recall)\n",
    "print(\"Training F1 score:\", train_f1)\n",
    "print(\"Testing accuracy:\", test_accuracy)\n",
    "print(\"Testing precision:\", test_precision)\n",
    "print(\"Testing recall:\", test_recall)\n",
    "print(\"Testing F1 score:\", test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27229d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The reults for the best parameters shows that the model is not overfitting (but may be underfitting), which indicates that this is the best possible\n",
    "## results for this data.\n",
    "## The fact that the GNB assumes that all features are normally distributed, affect the model alot. Other NB variations \n",
    "## are not suitable for our data \n",
    "## Another approach that we could have done, but we couldn't due to tigh project time, is to normalize the distribution \n",
    "## the features that are not normally distributed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
