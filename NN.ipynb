{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea71a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "161a5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "\n",
    "data=pd.read_csv('preprocessed_UK_Accidents_2009_updated.csv',index_col='accident_index')\n",
    "data=data.drop('seasons_ranges',axis=1)\n",
    "x = data.drop('accident_severity', axis=1) \n",
    "y = data['accident_severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d28ed121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalling data\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9bb41009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "priciple_component_analayzer = PCA(n_components=15) # based on domain knowledge from feature extraction notebook\n",
    "x_pca = priciple_component_analayzer.fit_transform(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78993a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Over sampling due to data imbalance \n",
    "oversampler = RandomOverSampler(random_state=10)\n",
    "x_resampled, y_resampled = oversampler.fit_resample(x_pca, y)\n",
    "x_resampled=pd.DataFrame(x_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b04693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.9683 - accuracy: 0.5134 - val_loss: 0.9343 - val_accuracy: 0.5356\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 16s 2ms/step - loss: 0.9027 - accuracy: 0.5559 - val_loss: 0.8824 - val_accuracy: 0.5658\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 16s 2ms/step - loss: 0.8588 - accuracy: 0.5830 - val_loss: 0.8490 - val_accuracy: 0.5847\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 16s 2ms/step - loss: 0.8303 - accuracy: 0.5982 - val_loss: 0.8220 - val_accuracy: 0.6019\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 16s 2ms/step - loss: 0.8105 - accuracy: 0.6091 - val_loss: 0.8059 - val_accuracy: 0.6125\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 16s 2ms/step - loss: 0.7953 - accuracy: 0.6174 - val_loss: 0.7948 - val_accuracy: 0.6168\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 16s 2ms/step - loss: 0.7823 - accuracy: 0.6238 - val_loss: 0.7907 - val_accuracy: 0.6155\n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.7728 - accuracy: 0.6287 - val_loss: 0.7791 - val_accuracy: 0.6267\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.7649 - accuracy: 0.6343 - val_loss: 0.7703 - val_accuracy: 0.6304\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 17s 2ms/step - loss: 0.7578 - accuracy: 0.6376 - val_loss: 0.7641 - val_accuracy: 0.6344\n",
      "8083/8083 [==============================] - 10s 1ms/step\n",
      "2526/2526 [==============================] - 3s 1ms/step\n",
      "Training accuracy: 0.641302919002513\n",
      "Training F1 score (micro): 0.641302919002513\n",
      "Training precision (micro): 0.641302919002513\n",
      "Training recall (micro): 0.641302919002513\n",
      "Test accuracy: 0.6366279429412711\n",
      "Test F1 score (micro): 0.6366279429412711\n",
      "Test precision (micro): 0.6366279429412711\n",
      "Test recall (micro): 0.6366279429412711\n"
     ]
    }
   ],
   "source": [
    "## resampling effect\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "input_dim = X_train.shape[1]\n",
    "y_train_new = np.subtract(y_train, 1)\n",
    "y_test_new = np.subtract(y_test, 1)\n",
    "y_val_new = np.subtract(y_val, 1)\n",
    "\n",
    "# Convert the new class labels to a one-hot encoded array\n",
    "y_train_onehot = to_categorical(y_train_new, num_classes=3)\n",
    "y_test_onehot = to_categorical(y_test_new, num_classes=3)\n",
    "y_val_onehot  =  to_categorical(y_val_new, num_classes=3)\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_onehot, epochs=10, batch_size=32, validation_data=(X_val, y_val_onehot))\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_classes = y_train_pred.argmax(axis=1)\n",
    "y_train_classes = y_train_onehot.argmax(axis=1)\n",
    "train_acc = accuracy_score(y_train_classes, y_train_pred_classes)\n",
    "train_f1_micro = f1_score(y_train_classes, y_train_pred_classes, average='micro')\n",
    "train_precision_micro = precision_score(y_train_classes, y_train_pred_classes, average='micro')\n",
    "train_recall_micro = recall_score(y_train_classes, y_train_pred_classes, average='micro')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_classes = y_test_pred.argmax(axis=1)\n",
    "y_test_classes = y_test_onehot.argmax(axis=1)\n",
    "test_acc = accuracy_score(y_test_classes, y_test_pred_classes)\n",
    "test_f1_micro = f1_score(y_test_classes, y_test_pred_classes, average='micro')\n",
    "test_precision_micro = precision_score(y_test_classes, y_test_pred_classes, average='micro')\n",
    "test_recall_micro = recall_score(y_test_classes, y_test_pred_classes, average='micro')\n",
    "\n",
    "# Print the results\n",
    "print('Training accuracy:', train_acc)\n",
    "print('Training F1 score (micro):', train_f1_micro)\n",
    "print('Training precision (micro):', train_precision_micro)\n",
    "print('Training recall (micro):', train_recall_micro)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test F1 score (micro):', test_f1_micro)\n",
    "print('Test precision (micro):', test_precision_micro)\n",
    "print('Test recall (micro):', test_recall_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31e87342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.3907614757863128, 2: 2.4805096165625384, 3: 26.489272632129776}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=y_train)\n",
    "class_weight_value = {class_labels[i]: weight for i, weight in enumerate(class_weights)}\n",
    "class_weight_value = {i-1: w for i, w in class_weight_value.items()}\n",
    "class_weight_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be858301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 1.0250 - accuracy: 0.4756 - val_loss: 0.9883 - val_accuracy: 0.4924\n",
      "Epoch 2/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 1.0001 - accuracy: 0.5029 - val_loss: 1.0359 - val_accuracy: 0.4720\n",
      "Epoch 3/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.9919 - accuracy: 0.5115 - val_loss: 0.9884 - val_accuracy: 0.5314\n",
      "Epoch 4/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.9866 - accuracy: 0.5232 - val_loss: 0.9563 - val_accuracy: 0.5506\n",
      "Epoch 5/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.9802 - accuracy: 0.5229 - val_loss: 1.0241 - val_accuracy: 0.4920\n",
      "Epoch 6/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.9743 - accuracy: 0.5291 - val_loss: 1.0417 - val_accuracy: 0.4967\n",
      "Epoch 7/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.9690 - accuracy: 0.5274 - val_loss: 0.9937 - val_accuracy: 0.5215\n",
      "Epoch 8/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.9651 - accuracy: 0.5283 - val_loss: 0.9582 - val_accuracy: 0.5364\n",
      "Epoch 9/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.9592 - accuracy: 0.5336 - val_loss: 0.9627 - val_accuracy: 0.5354\n",
      "Epoch 10/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.9512 - accuracy: 0.5279 - val_loss: 0.9079 - val_accuracy: 0.5652\n",
      "3164/3164 [==============================] - 4s 1ms/step\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "Training accuracy: 0.574820726575927\n",
      "Training F1 score (micro): 0.574820726575927\n",
      "Training precision (micro): 0.574820726575927\n",
      "Training recall (micro): 0.574820726575927\n",
      "Test accuracy: 0.574417649103954\n",
      "Test F1 score (micro): 0.574417649103954\n",
      "Test precision (micro): 0.574417649103954\n",
      "Test recall (micro): 0.574417649103954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "input_dim = X_train.shape[1]\n",
    "y_train_new = np.subtract(y_train, 1)\n",
    "y_test_new = np.subtract(y_test, 1)\n",
    "y_val_new = np.subtract(y_val, 1)\n",
    "class_labels = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=y_train)\n",
    "class_weight_value = {class_labels[i]: weight for i, weight in enumerate(class_weights)}\n",
    "class_weight_value = {i-1: w for i, w in class_weight_value.items()}\n",
    "\n",
    "# Convert the new class labels to a one-hot encoded array\n",
    "y_train_onehot = to_categorical(y_train_new, num_classes=3)\n",
    "y_test_onehot = to_categorical(y_test_new, num_classes=3)\n",
    "y_val_onehot  =  to_categorical(y_val_new, num_classes=3)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_onehot, epochs=10, batch_size=32, validation_data=(X_val, y_val_onehot),class_weight=class_weight_value)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_classes = y_train_pred.argmax(axis=1)\n",
    "y_train_classes = y_train_onehot.argmax(axis=1)\n",
    "train_acc = accuracy_score(y_train_classes, y_train_pred_classes)\n",
    "train_f1_micro = f1_score(y_train_classes, y_train_pred_classes, average='micro')\n",
    "train_precision_micro = precision_score(y_train_classes, y_train_pred_classes, average='micro')\n",
    "train_recall_micro = recall_score(y_train_classes, y_train_pred_classes, average='micro')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_classes = y_test_pred.argmax(axis=1)\n",
    "y_test_classes = y_test_onehot.argmax(axis=1)\n",
    "test_acc = accuracy_score(y_test_classes, y_test_pred_classes)\n",
    "test_f1_micro = f1_score(y_test_classes, y_test_pred_classes, average='micro')\n",
    "test_precision_micro = precision_score(y_test_classes, y_test_pred_classes, average='micro')\n",
    "test_recall_micro = recall_score(y_test_classes, y_test_pred_classes, average='micro')\n",
    "\n",
    "# Print the results\n",
    "print('Training accuracy:', train_acc)\n",
    "print('Training F1 score (micro):', train_f1_micro)\n",
    "print('Training precision (micro):', train_precision_micro)\n",
    "print('Training recall (micro):', train_recall_micro)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test F1 score (micro):', test_f1_micro)\n",
    "print('Test precision (micro):', test_precision_micro)\n",
    "print('Test recall (micro):', test_recall_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78d5102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Architecture: [64, 32]\n",
      "Epoch 1/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.4520 - accuracy: 0.8510 - val_loss: 0.4495 - val_accuracy: 0.8488\n",
      "Epoch 2/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4411 - accuracy: 0.8530 - val_loss: 0.4468 - val_accuracy: 0.8488\n",
      "Epoch 3/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4386 - accuracy: 0.8530 - val_loss: 0.4445 - val_accuracy: 0.8488\n",
      "Epoch 4/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4370 - accuracy: 0.8530 - val_loss: 0.4450 - val_accuracy: 0.8488\n",
      "Epoch 5/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4357 - accuracy: 0.8530 - val_loss: 0.4462 - val_accuracy: 0.8488\n",
      "Epoch 6/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4348 - accuracy: 0.8530 - val_loss: 0.4451 - val_accuracy: 0.8488\n",
      "Epoch 7/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4338 - accuracy: 0.8530 - val_loss: 0.4443 - val_accuracy: 0.8488\n",
      "Epoch 8/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4328 - accuracy: 0.8530 - val_loss: 0.4442 - val_accuracy: 0.8488\n",
      "Epoch 9/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4324 - accuracy: 0.8531 - val_loss: 0.4438 - val_accuracy: 0.8488\n",
      "Epoch 10/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4319 - accuracy: 0.8531 - val_loss: 0.4438 - val_accuracy: 0.8489\n",
      "3164/3164 [==============================] - 4s 1ms/step\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "Training accuracy: 3.95092945615456e-05\n",
      "Training F1 score (micro): 3.95092945615456e-05\n",
      "Training precision (micro): 3.95092945615456e-05\n",
      "Training recall (micro): 3.95092945615456e-05\n",
      "Test accuracy: 0.00012642624608868801\n",
      "Test F1 score (micro): 0.00012642624608868801\n",
      "Test precision (micro): 0.00012642624608868801\n",
      "Test recall (micro): 0.00012642624608868801\n",
      "\n",
      "Model 2\n",
      "Architecture: [128, 64, 32]\n",
      "Epoch 1/10\n",
      "3164/3164 [==============================] - 8s 2ms/step - loss: 0.4493 - accuracy: 0.8519 - val_loss: 0.4475 - val_accuracy: 0.8488\n",
      "Epoch 2/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.4408 - accuracy: 0.8530 - val_loss: 0.4458 - val_accuracy: 0.8488\n",
      "Epoch 3/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.4381 - accuracy: 0.8530 - val_loss: 0.4464 - val_accuracy: 0.8488\n",
      "Epoch 4/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.4363 - accuracy: 0.8530 - val_loss: 0.4466 - val_accuracy: 0.8488\n",
      "Epoch 5/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.4349 - accuracy: 0.8530 - val_loss: 0.4430 - val_accuracy: 0.8488\n",
      "Epoch 6/10\n",
      "3164/3164 [==============================] - 8s 2ms/step - loss: 0.4339 - accuracy: 0.8530 - val_loss: 0.4451 - val_accuracy: 0.8488\n",
      "Epoch 7/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.4327 - accuracy: 0.8530 - val_loss: 0.4458 - val_accuracy: 0.8488\n",
      "Epoch 8/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.4319 - accuracy: 0.8530 - val_loss: 0.4434 - val_accuracy: 0.8488\n",
      "Epoch 9/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.4307 - accuracy: 0.8530 - val_loss: 0.4438 - val_accuracy: 0.8488\n",
      "Epoch 10/10\n",
      "3164/3164 [==============================] - 7s 2ms/step - loss: 0.4294 - accuracy: 0.8530 - val_loss: 0.4455 - val_accuracy: 0.8488\n",
      "3164/3164 [==============================] - 4s 1ms/step\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "Training accuracy: 0.0\n",
      "Training F1 score (micro): 0.0\n",
      "Training precision (micro): 0.0\n",
      "Training recall (micro): 0.0\n",
      "Test accuracy: 0.0\n",
      "Test F1 score (micro): 0.0\n",
      "Test precision (micro): 0.0\n",
      "Test recall (micro): 0.0\n",
      "\n",
      "Model 3\n",
      "Architecture: [256, 128, 64, 32]\n",
      "Epoch 1/10\n",
      "3164/3164 [==============================] - 9s 3ms/step - loss: 0.4487 - accuracy: 0.8523 - val_loss: 0.4466 - val_accuracy: 0.8488\n",
      "Epoch 2/10\n",
      "3164/3164 [==============================] - 8s 2ms/step - loss: 0.4409 - accuracy: 0.8530 - val_loss: 0.4438 - val_accuracy: 0.8488\n",
      "Epoch 3/10\n",
      "3164/3164 [==============================] - 8s 3ms/step - loss: 0.4383 - accuracy: 0.8530 - val_loss: 0.4452 - val_accuracy: 0.8488\n",
      "Epoch 4/10\n",
      "3164/3164 [==============================] - 8s 3ms/step - loss: 0.4365 - accuracy: 0.8530 - val_loss: 0.4446 - val_accuracy: 0.8488\n",
      "Epoch 5/10\n",
      "3164/3164 [==============================] - 8s 3ms/step - loss: 0.4351 - accuracy: 0.8530 - val_loss: 0.4436 - val_accuracy: 0.8488\n",
      "Epoch 6/10\n",
      "3164/3164 [==============================] - 9s 3ms/step - loss: 0.4340 - accuracy: 0.8530 - val_loss: 0.4433 - val_accuracy: 0.8488\n",
      "Epoch 7/10\n",
      "3164/3164 [==============================] - 9s 3ms/step - loss: 0.4329 - accuracy: 0.8530 - val_loss: 0.4436 - val_accuracy: 0.8488\n",
      "Epoch 8/10\n",
      "3164/3164 [==============================] - 8s 3ms/step - loss: 0.4319 - accuracy: 0.8530 - val_loss: 0.4453 - val_accuracy: 0.8488\n",
      "Epoch 9/10\n",
      "3164/3164 [==============================] - 9s 3ms/step - loss: 0.4307 - accuracy: 0.8530 - val_loss: 0.4432 - val_accuracy: 0.8488\n",
      "Epoch 10/10\n",
      "3164/3164 [==============================] - 9s 3ms/step - loss: 0.4295 - accuracy: 0.8531 - val_loss: 0.4445 - val_accuracy: 0.8488\n",
      "3164/3164 [==============================] - 5s 1ms/step\n",
      "989/989 [==============================] - 1s 1ms/step\n",
      "Training accuracy: 9.8773236403864e-06\n",
      "Training F1 score (micro): 9.8773236403864e-06\n",
      "Training precision (micro): 9.8773236403864e-06\n",
      "Training recall (micro): 9.8773236403864e-06\n",
      "Test accuracy: 3.1606561522172003e-05\n",
      "Test F1 score (micro): 3.1606561522172003e-05\n",
      "Test precision (micro): 3.1606561522172003e-05\n",
      "Test recall (micro): 3.1606561522172003e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "input_dim = X_train.shape[1]\n",
    "y_train_new = np.subtract(y_train, 1)\n",
    "y_test_new = np.subtract(y_test, 1)\n",
    "y_val_new = np.subtract(y_val, 1)\n",
    "class_labels = np.unique(y_train)\n",
    "\n",
    "\n",
    "# Convert the new class labels to a one-hot encoded array\n",
    "y_train_onehot = to_categorical(y_train_new, num_classes=3)\n",
    "y_test_onehot = to_categorical(y_test_new, num_classes=3)\n",
    "y_val_onehot  =  to_categorical(y_val_new, num_classes=3)\n",
    "\n",
    "\n",
    "# Define a list of model architectures to try\n",
    "architectures = [\n",
    "    [64, 32],\n",
    "    [128, 64, 32],\n",
    "    [256, 128, 64, 32],\n",
    "]\n",
    "\n",
    "# Loop through the model architectures and evaluate their performance\n",
    "for i, architecture in enumerate(architectures):\n",
    "    print('Model', i+1)\n",
    "    print('Architecture:', architecture)\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    for j, layer_size in enumerate(architecture):\n",
    "        if j == 0:\n",
    "            model.add(Dense(layer_size, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "        else:\n",
    "            model.add(Dense(layer_size, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train_onehot, epochs=10, batch_size=32, validation_data=(X_val, y_val_onehot))\n",
    "\n",
    "    # Evaluate the model on the training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_pred_classes = y_train_pred.argmax(axis=1)\n",
    "    train_acc = accuracy_score(y_train, y_train_pred_classes)\n",
    "    train_f1_micro = f1_score(y_train, y_train_pred_classes, average='micro')\n",
    "    train_precision_micro = precision_score(y_train, y_train_pred_classes, average='micro')\n",
    "    train_recall_micro = recall_score(y_train, y_train_pred_classes, average='micro')\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_classes = y_test_pred.argmax(axis=1)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred_classes)\n",
    "    test_f1_micro = f1_score(y_test, y_test_pred_classes, average='micro')\n",
    "    test_precision_micro = precision_score(y_test, y_test_pred_classes, average='micro')\n",
    "    test_recall_micro = recall_score(y_test, y_test_pred_classes, average='micro')\n",
    "\n",
    "    # Print the results\n",
    "    print('Training accuracy:', train_acc)\n",
    "    print('Training F1 score (micro):', train_f1_micro)\n",
    "    print('Training precision (micro):', train_precision_micro)\n",
    "    print('Training recall (micro):', train_recall_micro)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    print('Test F1 score (micro):', test_f1_micro)\n",
    "    print('Test precision (micro):', test_precision_micro)\n",
    "    print('Test recall (micro):', test_recall_micro)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "379b06ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3164/3164 [==============================] - 69s 3ms/step - loss: 0.4566 - accuracy: 0.8513 - val_loss: 0.4732 - val_accuracy: 0.8516\n",
      "Epoch 2/100\n",
      "3164/3164 [==============================] - 8s 3ms/step - loss: 0.4505 - accuracy: 0.8516 - val_loss: 0.4483 - val_accuracy: 0.8516\n",
      "Epoch 3/100\n",
      "3164/3164 [==============================] - 8s 3ms/step - loss: 0.4516 - accuracy: 0.8516 - val_loss: 0.4968 - val_accuracy: 0.8516\n",
      "Epoch 4/100\n",
      "3164/3164 [==============================] - 8s 3ms/step - loss: 0.4504 - accuracy: 0.8516 - val_loss: 0.4504 - val_accuracy: 0.8516\n",
      "Epoch 5/100\n",
      "3164/3164 [==============================] - 8s 3ms/step - loss: 0.4517 - accuracy: 0.8516 - val_loss: 0.4490 - val_accuracy: 0.8516\n",
      "Epoch 6/100\n",
      "2614/3164 [=======================>......] - ETA: 1s - loss: 0.4519 - accuracy: 0.8509"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18048\\883590428.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_onehot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# Evaluate the model on the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, y, test_size=0.2, random_state=42,stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42,stratify=y_train)\n",
    "input_dim = X_train.shape[1]\n",
    "y_train_new = np.subtract(y_train, 1)\n",
    "y_test_new = np.subtract(y_test, 1)\n",
    "y_val_new = np.subtract(y_val, 1)\n",
    "\n",
    "\n",
    "# Convert the new class labels to a one-hot encoded array\n",
    "y_train_onehot = to_categorical(y_train_new, num_classes=3)\n",
    "y_test_onehot = to_categorical(y_test_new, num_classes=3)\n",
    "y_val_onehot  =  to_categorical(y_val_new, num_classes=3)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_onehot, epochs=100, batch_size=32, validation_data=(X_val, y_val_onehot))\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred_classes = y_train_pred.argmax(axis=1)\n",
    "y_train_classes = y_train_onehot.argmax(axis=1)\n",
    "train_acc = accuracy_score(y_train_classes, y_train_pred_classes)\n",
    "train_f1_micro = f1_score(y_train_classes, y_train_pred_classes, average='micro')\n",
    "train_precision_micro = precision_score(y_train_classes, y_train_pred_classes, average='micro')\n",
    "train_recall_micro = recall_score(y_train_classes, y_train_pred_classes, average='micro')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_classes = y_test_pred.argmax(axis=1)\n",
    "y_test_classes = y_test_onehot.argmax(axis=1)\n",
    "test_acc = accuracy_score(y_test_classes, y_test_pred_classes)\n",
    "test_f1_micro = f1_score(y_test_classes, y_test_pred_classes, average='micro')\n",
    "test_precision_micro = precision_score(y_test_classes, y_test_pred_classes, average='micro')\n",
    "test_recall_micro = recall_score(y_test_classes, y_test_pred_classes, average='micro')\n",
    "\n",
    "# Print the results\n",
    "print('Training accuracy:', train_acc)\n",
    "print('Training F1 score (micro):', train_f1_micro)\n",
    "print('Training precision (micro):', train_precision_micro)\n",
    "print('Training recall (micro):', train_recall_micro)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test F1 score (micro):', test_f1_micro)\n",
    "print('Test precision (micro):', test_precision_micro)\n",
    "print('Test recall (micro):', test_recall_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ca59ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4559 - accuracy: 0.8507\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4438 - accuracy: 0.8518\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4406 - accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4387 - accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4373 - accuracy: 0.8518\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4361 - accuracy: 0.8518\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4348 - accuracy: 0.8519\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4340 - accuracy: 0.8518\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4329 - accuracy: 0.8519\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4322 - accuracy: 0.8519\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4478 - accuracy: 0.8510\n",
      "[CV 1/3] END learning_rate=0.001, num_hidden_layers=1;, score=0.851 total time=  37.9s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4585 - accuracy: 0.8488\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4442 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4413 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4397 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4378 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4370 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4360 - accuracy: 0.8513\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4352 - accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4344 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4340 - accuracy: 0.8514\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4435 - accuracy: 0.8519\n",
      "[CV 2/3] END learning_rate=0.001, num_hidden_layers=1;, score=0.852 total time=  37.3s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4616 - accuracy: 0.8486\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4475 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4450 - accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4431 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4418 - accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4405 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4392 - accuracy: 0.8515\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4382 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4373 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4363 - accuracy: 0.8515\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4380 - accuracy: 0.8519\n",
      "[CV 3/3] END learning_rate=0.001, num_hidden_layers=1;, score=0.852 total time=  37.5s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4569 - accuracy: 0.8500\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4435 - accuracy: 0.8519\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4408 - accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4383 - accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4363 - accuracy: 0.8519\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4352 - accuracy: 0.8518\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4339 - accuracy: 0.8518\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4327 - accuracy: 0.8518\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4318 - accuracy: 0.8519\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4309 - accuracy: 0.8518\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4460 - accuracy: 0.8507\n",
      "[CV 1/3] END learning_rate=0.001, num_hidden_layers=2;, score=0.851 total time=  42.0s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4553 - accuracy: 0.8511\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4435 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4408 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4388 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4376 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4362 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4348 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4335 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4323 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4310 - accuracy: 0.8514\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4482 - accuracy: 0.8519\n",
      "[CV 2/3] END learning_rate=0.001, num_hidden_layers=2;, score=0.852 total time=  42.1s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4567 - accuracy: 0.8514\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4465 - accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4437 - accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4421 - accuracy: 0.8515\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4400 - accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4388 - accuracy: 0.8515\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4375 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4358 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4348 - accuracy: 0.8515\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4336 - accuracy: 0.8515\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4393 - accuracy: 0.8518\n",
      "[CV 3/3] END learning_rate=0.001, num_hidden_layers=2;, score=0.852 total time=  42.2s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4530 - accuracy: 0.8512\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4432 - accuracy: 0.8519\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4406 - accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4386 - accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4366 - accuracy: 0.8519\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4356 - accuracy: 0.8519\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4341 - accuracy: 0.8519\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4329 - accuracy: 0.8519\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4311 - accuracy: 0.8519\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4303 - accuracy: 0.8519\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4444 - accuracy: 0.8510\n",
      "[CV 1/3] END learning_rate=0.001, num_hidden_layers=3;, score=0.851 total time=  46.7s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4549 - accuracy: 0.8503\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4444 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4411 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4387 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4374 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4362 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4347 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4331 - accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4322 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4305 - accuracy: 0.8514\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4456 - accuracy: 0.8519\n",
      "[CV 2/3] END learning_rate=0.001, num_hidden_layers=3;, score=0.852 total time=  47.4s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4565 - accuracy: 0.8507\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4461 - accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4438 - accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4419 - accuracy: 0.8515\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4410 - accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4393 - accuracy: 0.8515\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4379 - accuracy: 0.8515\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4370 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4353 - accuracy: 0.8515\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4343 - accuracy: 0.8515\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4376 - accuracy: 0.8518\n",
      "[CV 3/3] END learning_rate=0.001, num_hidden_layers=3;, score=0.852 total time=  45.5s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4525 - accuracy: 0.8517\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4447 - accuracy: 0.8518\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4439 - accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4435 - accuracy: 0.8515\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4425 - accuracy: 0.8516\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4434 - accuracy: 0.8517\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4429 - accuracy: 0.8515\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4424 - accuracy: 0.8517\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4419 - accuracy: 0.8517\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4427 - accuracy: 0.8517\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4488 - accuracy: 0.8510\n",
      "[CV 1/3] END learning_rate=0.01, num_hidden_layers=1;, score=0.851 total time=  37.8s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4528 - accuracy: 0.8509\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4464 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4453 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4446 - accuracy: 0.8512\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4440 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4432 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4436 - accuracy: 0.8513\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4424 - accuracy: 0.8513\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4422 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4425 - accuracy: 0.8513\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4460 - accuracy: 0.8519\n",
      "[CV 2/3] END learning_rate=0.01, num_hidden_layers=1;, score=0.852 total time=  37.1s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4560 - accuracy: 0.8513\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4484 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4491 - accuracy: 0.8513\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4474 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4472 - accuracy: 0.8513\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4463 - accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4457 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4457 - accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4452 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4451 - accuracy: 0.8513\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4396 - accuracy: 0.8517\n",
      "[CV 3/3] END learning_rate=0.01, num_hidden_layers=1;, score=0.852 total time=  37.7s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4531 - accuracy: 0.8518\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4458 - accuracy: 0.8518\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4450 - accuracy: 0.8517\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4440 - accuracy: 0.8518\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4443 - accuracy: 0.8517\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4440 - accuracy: 0.8518\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4451 - accuracy: 0.8518\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4434 - accuracy: 0.8518\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4434 - accuracy: 0.8518\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4441 - accuracy: 0.8518\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4521 - accuracy: 0.8510\n",
      "[CV 1/3] END learning_rate=0.01, num_hidden_layers=2;, score=0.851 total time=  41.5s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4537 - accuracy: 0.8511\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4474 - accuracy: 0.8513\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4462 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4454 - accuracy: 0.8513\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4449 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4445 - accuracy: 0.8515\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4439 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4440 - accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4432 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4443 - accuracy: 0.8514\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4471 - accuracy: 0.8519\n",
      "[CV 2/3] END learning_rate=0.01, num_hidden_layers=2;, score=0.852 total time=  41.4s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4561 - accuracy: 0.8510\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4495 - accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4480 - accuracy: 0.8513\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4476 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4465 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4467 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4469 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4480 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4469 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4460 - accuracy: 0.8515\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4415 - accuracy: 0.8518\n",
      "[CV 3/3] END learning_rate=0.01, num_hidden_layers=2;, score=0.852 total time=  42.1s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4526 - accuracy: 0.8517\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4465 - accuracy: 0.8518\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4451 - accuracy: 0.8517\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4490 - accuracy: 0.8518\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4471 - accuracy: 0.8517\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4455 - accuracy: 0.8517\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4452 - accuracy: 0.8518\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4450 - accuracy: 0.8517\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4448 - accuracy: 0.8517\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4469 - accuracy: 0.8518\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4492 - accuracy: 0.8510\n",
      "[CV 1/3] END learning_rate=0.01, num_hidden_layers=3;, score=0.851 total time=  46.9s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4547 - accuracy: 0.8511\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4492 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4469 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4463 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4469 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4454 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4461 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4440 - accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4464 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4441 - accuracy: 0.8514\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4439 - accuracy: 0.8519\n",
      "[CV 2/3] END learning_rate=0.01, num_hidden_layers=3;, score=0.852 total time=  48.1s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4572 - accuracy: 0.8514\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4515 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4488 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4483 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4488 - accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4501 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4500 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4491 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4487 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4489 - accuracy: 0.8515\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4439 - accuracy: 0.8518\n",
      "[CV 3/3] END learning_rate=0.01, num_hidden_layers=3;, score=0.852 total time=  47.8s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4728 - accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4671 - accuracy: 0.8518\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4658 - accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4659 - accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4662 - accuracy: 0.8519\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4663 - accuracy: 0.8519\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4659 - accuracy: 0.8519\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4662 - accuracy: 0.8519\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4655 - accuracy: 0.8519\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4658 - accuracy: 0.8519\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4648 - accuracy: 0.8510\n",
      "[CV 1/3] END learning_rate=0.1, num_hidden_layers=1;, score=0.851 total time=  37.9s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4726 - accuracy: 0.8512\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4661 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4661 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4659 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4668 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4664 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4666 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4665 - accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4659 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4664 - accuracy: 0.8514\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4685 - accuracy: 0.8519\n",
      "[CV 2/3] END learning_rate=0.1, num_hidden_layers=1;, score=0.852 total time=  37.9s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4721 - accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4672 - accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4680 - accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 3s 2ms/step - loss: 0.4681 - accuracy: 0.8515\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4680 - accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4676 - accuracy: 0.8515\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4676 - accuracy: 0.8515\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4675 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4674 - accuracy: 0.8515\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4675 - accuracy: 0.8515\n",
      "1055/1055 [==============================] - 2s 1ms/step - loss: 0.4694 - accuracy: 0.8518\n",
      "[CV 3/3] END learning_rate=0.1, num_hidden_layers=1;, score=0.852 total time=  38.0s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4733 - accuracy: 0.8512\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4662 - accuracy: 0.8519\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4656 - accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4662 - accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4657 - accuracy: 0.8519\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4656 - accuracy: 0.8519\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4660 - accuracy: 0.8519\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4656 - accuracy: 0.8519\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4666 - accuracy: 0.8519\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4656 - accuracy: 0.8519\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4659 - accuracy: 0.8510\n",
      "[CV 1/3] END learning_rate=0.1, num_hidden_layers=2;, score=0.851 total time=  42.2s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4725 - accuracy: 0.8509\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4658 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4662 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4665 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4665 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4665 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4663 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4666 - accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4662 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4659 - accuracy: 0.8514\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4645 - accuracy: 0.8519\n",
      "[CV 2/3] END learning_rate=0.1, num_hidden_layers=2;, score=0.852 total time=  42.3s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4752 - accuracy: 0.8508\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4680 - accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4677 - accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4674 - accuracy: 0.8515\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4677 - accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4673 - accuracy: 0.8515\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4674 - accuracy: 0.8515\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4675 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4676 - accuracy: 0.8515\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4674 - accuracy: 0.8515\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4617 - accuracy: 0.8518\n",
      "[CV 3/3] END learning_rate=0.1, num_hidden_layers=2;, score=0.852 total time=  43.2s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4790 - accuracy: 0.8511\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4658 - accuracy: 0.8519\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4660 - accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4660 - accuracy: 0.8519\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4658 - accuracy: 0.8519\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4658 - accuracy: 0.8519\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4658 - accuracy: 0.8519\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4658 - accuracy: 0.8519\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4658 - accuracy: 0.8519\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4661 - accuracy: 0.8519\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4649 - accuracy: 0.8510\n",
      "[CV 1/3] END learning_rate=0.1, num_hidden_layers=3;, score=0.851 total time=  47.3s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4746 - accuracy: 0.8509\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4661 - accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4663 - accuracy: 0.8514\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4660 - accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4662 - accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4665 - accuracy: 0.8514\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4664 - accuracy: 0.8514\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4658 - accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4663 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4663 - accuracy: 0.8514\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4723 - accuracy: 0.8519\n",
      "[CV 2/3] END learning_rate=0.1, num_hidden_layers=3;, score=0.852 total time=  46.4s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\express\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110/2110 [==============================] - 5s 2ms/step - loss: 0.4788 - accuracy: 0.8506\n",
      "Epoch 2/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4676 - accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4676 - accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4683 - accuracy: 0.8515\n",
      "Epoch 5/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4678 - accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4679 - accuracy: 0.8515\n",
      "Epoch 7/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4681 - accuracy: 0.8515\n",
      "Epoch 8/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4674 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4676 - accuracy: 0.8515\n",
      "Epoch 10/10\n",
      "2110/2110 [==============================] - 4s 2ms/step - loss: 0.4677 - accuracy: 0.8515\n",
      "1055/1055 [==============================] - 2s 2ms/step - loss: 0.4657 - accuracy: 0.8518\n",
      "[CV 3/3] END learning_rate=0.1, num_hidden_layers=3;, score=0.852 total time=  45.7s\n",
      "Epoch 1/10\n",
      "3164/3164 [==============================] - 6s 2ms/step - loss: 0.4523 - accuracy: 0.8515\n",
      "Epoch 2/10\n",
      "3164/3164 [==============================] - 5s 2ms/step - loss: 0.4431 - accuracy: 0.8516\n",
      "Epoch 3/10\n",
      "3164/3164 [==============================] - 5s 2ms/step - loss: 0.4407 - accuracy: 0.8516\n",
      "Epoch 4/10\n",
      "3164/3164 [==============================] - 5s 2ms/step - loss: 0.4392 - accuracy: 0.8516\n",
      "Epoch 5/10\n",
      "3164/3164 [==============================] - 5s 2ms/step - loss: 0.4381 - accuracy: 0.8515\n",
      "Epoch 6/10\n",
      "3164/3164 [==============================] - 5s 2ms/step - loss: 0.4372 - accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "3164/3164 [==============================] - 5s 2ms/step - loss: 0.4363 - accuracy: 0.8516\n",
      "Epoch 8/10\n",
      "3164/3164 [==============================] - 5s 2ms/step - loss: 0.4358 - accuracy: 0.8515\n",
      "Epoch 9/10\n",
      "3164/3164 [==============================] - 5s 2ms/step - loss: 0.4349 - accuracy: 0.8514\n",
      "Epoch 10/10\n",
      "3164/3164 [==============================] - 5s 2ms/step - loss: 0.4344 - accuracy: 0.8515\n",
      "Best: 0.851593 using {'learning_rate': 0.001, 'num_hidden_layers': 1}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a function that creates a Keras model\n",
    "def create_model(learning_rate, num_hidden_layers):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(input_dim,), activation='relu'))\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "num_hidden_layers = [1, 2, 3]\n",
    "\n",
    "# Create a KerasClassifier object\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32)\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = dict(learning_rate=learning_rates, num_hidden_layers=num_hidden_layers)\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3,verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The search grid shows that different architectures and parameters are not changing anything in the perfomrance, unfortunately\n",
    "## We will not preceding with this model as NNs needs alot of data engineering work to do and this is beyond our knowledge "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
